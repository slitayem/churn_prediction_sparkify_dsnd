{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn prediction for Sparkify Music Service\n",
    "\n",
    "# <center>3. Features engineering and modeling </center>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "3. [Feature Engineering]((#feature_eng))\n",
    "4. [Model training and evaluation]((#modeling))\n",
    "5. [Conclusion]((#conclusion))\n",
    "\n",
    "\n",
    "In the data exploration step we could extract potential indicators that can be used to distinguish between churning and engaged customers. \n",
    "\n",
    "We observed that the number of visits to some of the pages could be used as indicators to to know if a customer is likely to churn or not. For example the engaged users were having more interactions on the service platform by visitng more often the `ThumbsUp` or `ThumbsDown` pages. Then we decide to use the following features to reflect the pages visits making difference between both types of users:\n",
    "\n",
    "- Binary feature with value equal to one if the number `ThumbsUp` page visits is greater than 20\n",
    "- Number of `ThumbsDown` page visits\n",
    "- Number of Roll Advert Page visits\n",
    "\n",
    "We observed that the `service usage` and level of engagemnt of the customer can be also a clear indicator. Which helped us to define the following features:\n",
    "\n",
    "- Average daily sessions duration\n",
    "- Average monthly sessions duration\n",
    "- Average daily Number of songs per session\n",
    "- Average daily Number of items per session\n",
    "- Daily number of songs over the last 20 days (vector of 20 values)\n",
    "- Daily number of sessions over the last 20 days (vector of 20 values)\n",
    "\n",
    "The decision in keeping the usage information over only the last `20 days` was a result of the check of the percentage of the dataset users that could be kept by number of days the customer have been using sparkify service. See the related analysis and plot in the data exploration part [here](#usage_days)\n",
    "\n",
    "One more feature that could help in having an idea about the customer satisfaction in using the service is to know whether the customer can find the artists songs he wants to listen to or not.\n",
    "\n",
    "- Number of unique artists the user listened to \n",
    "\n",
    "We also decided to have some features to characterize the user subscription:\n",
    "\n",
    "- Last level of the user (Paid or Free)\n",
    "- User Account age in days: usage duration since first log event day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from time import time\n",
    "import pprint\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnan, when, count, col, udf\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType, DoubleType, LongType, IntegerType, DateType, TimestampType\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier\n",
    "from pyspark.ml.classification import GBTClassifier, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import utils\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Sparkify\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.98:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Sparkify</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc567b1c4d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %store -r events_data_path\n",
    "events_data_path = \"../data/mini_sparkify_event_data.json\"\n",
    "events_df = utils.load_and_clean_data(spark, events_data_path)\n",
    "events_df = utils.add_churn_column(events_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>3. Features engineering <a id='feature_eng'></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Service usage over the last 20 days\n",
    "### Number of songs per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_days_df = utils.get_data_last_ndays(events_df, page_filter=\"NextSong\")\n",
    "songs_last20days_df = usage_days_df \\\n",
    "    .join(events_df, events_df.userId == usage_days_df.userId) \\\n",
    "    .where(events_df[\"date\"].between(col('20_days_before') + 1, col('last_day'))) \\\n",
    "    .groupby([events_df.userId, events_df.date, col('last_day')]).count() \\\n",
    "    .withColumn(\"date_index\", utils.account_age_in_days(col(\"last_day\"), col(\"date\"))) \\\n",
    "    .withColumn(\"date_index\", col(\"date_index\").cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_last20days_features = songs_last20days_df.toPandas()\\\n",
    "    .groupby('userId').apply(lambda x: utils.vector_builder(x, ['count', 'date_index'])).reset_index()\n",
    "songs_last20days_features.rename(\n",
    "    columns={index: \"d_songs_{}\".format(index) for index in range(0, 20)},\n",
    "    inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_days_df = utils.get_data_last_ndays(events_df)\n",
    "sessions_last20days_df = usage_days_df \\\n",
    "    .join(events_df, events_df.userId == usage_days_df.userId) \\\n",
    "    .where(events_df[\"date\"].between(col('20_days_before') + 1, col('last_day'))) \\\n",
    "    .groupby([events_df.userId,\n",
    "              events_df.date, \"sessionId\", col(\"last_day\")\n",
    "    ]).count().groupby(events_df.date, \"userId\", col(\"last_day\"))\\\n",
    "    .mean(\"count\") \\\n",
    "    .withColumnRenamed(\"avg(count)\", \"avg_sessions\")\\\n",
    "    .withColumn(\"date_index\", utils.account_age_in_days(col(\"last_day\"), col(\"date\")).cast('int')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>d_sessions_0</th>\n",
       "      <th>d_sessions_1</th>\n",
       "      <th>d_sessions_2</th>\n",
       "      <th>d_sessions_3</th>\n",
       "      <th>d_sessions_4</th>\n",
       "      <th>d_sessions_5</th>\n",
       "      <th>d_sessions_6</th>\n",
       "      <th>d_sessions_7</th>\n",
       "      <th>d_sessions_8</th>\n",
       "      <th>...</th>\n",
       "      <th>d_sessions_10</th>\n",
       "      <th>d_sessions_11</th>\n",
       "      <th>d_sessions_12</th>\n",
       "      <th>d_sessions_13</th>\n",
       "      <th>d_sessions_14</th>\n",
       "      <th>d_sessions_15</th>\n",
       "      <th>d_sessions_16</th>\n",
       "      <th>d_sessions_17</th>\n",
       "      <th>d_sessions_18</th>\n",
       "      <th>d_sessions_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  d_sessions_0  d_sessions_1  d_sessions_2  d_sessions_3  \\\n",
       "0      10           0.0          95.0           0.0           0.0   \n",
       "1     100           0.0          91.0         196.0           0.0   \n",
       "2  100002           0.0           1.0           0.0           0.0   \n",
       "\n",
       "   d_sessions_4  d_sessions_5  d_sessions_6  d_sessions_7  d_sessions_8  ...  \\\n",
       "0          21.0          57.0           0.0           0.0           0.0  ...   \n",
       "1           0.0          23.0           0.0           0.0          30.0  ...   \n",
       "2           0.0           0.0           0.0           0.0           0.0  ...   \n",
       "\n",
       "   d_sessions_10  d_sessions_11  d_sessions_12  d_sessions_13  d_sessions_14  \\\n",
       "0            0.0            0.0            0.0            0.0            0.0   \n",
       "1           66.0          169.0          109.0            0.0            0.0   \n",
       "2            0.0            0.0            0.0            0.0            0.0   \n",
       "\n",
       "   d_sessions_15  d_sessions_16  d_sessions_17  d_sessions_18  d_sessions_19  \n",
       "0            0.0            0.0           78.0            0.0            0.0  \n",
       "1           36.0          125.0           86.0            7.0            0.0  \n",
       "2            0.0            0.0            0.0            0.0           75.0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions_last20days_features = sessions_last20days_df.toPandas()\\\n",
    "    .groupby('userId').apply(\n",
    "        lambda x: utils.vector_builder(x, ['avg_sessions', 'date_index']))\\\n",
    "    .reset_index()\n",
    "sessions_last20days_features.rename(\n",
    "    columns={index: \"d_sessions_{}\".format(index) for index in range(0, 20)},\n",
    "    inplace=True)\n",
    "sessions_last20days_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users 190\n"
     ]
    }
   ],
   "source": [
    "users_ids = sessions_last20days_df.select(\"userId\").distinct().rdd.map(lambda r: r[0]).collect()\n",
    "print(\"Number of unique users\", len(sessions_last20days_features.userId.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keep only users with account age older than 20 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_df = events_df[events_df.userId.isin(users_ids)]\n",
    "nb_users = events_df.select('userId').distinct().count()\n",
    "nb_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of days since user registration: `registration_days`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "registration_df = utils.registration_days(events_df)\n",
    "assert registration_df.select('userId').distinct().count() == nb_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>registration_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100010</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100010</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100010</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100010</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100010</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  registration_days\n",
       "0  100010                 55\n",
       "1  100010                 55\n",
       "2  100010                 55\n",
       "3  100010                 55\n",
       "4  100010                 55"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(registration_df.take(5), columns=registration_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Daily and Monthly session duration per user\" `avg_daily_session_duration` and `avg_monthly_session_duration`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>avg_daily_session_duration</th>\n",
       "      <th>avg_monthly_session_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100010</td>\n",
       "      <td>9269.000000</td>\n",
       "      <td>9693.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200002</td>\n",
       "      <td>11924.250000</td>\n",
       "      <td>21529.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124</td>\n",
       "      <td>25218.162037</td>\n",
       "      <td>35410.519231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>5258.428571</td>\n",
       "      <td>5003.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>24441.500000</td>\n",
       "      <td>31866.222222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  avg_daily_session_duration  avg_monthly_session_duration\n",
       "0  100010                 9269.000000                   9693.500000\n",
       "1  200002                11924.250000                  21529.200000\n",
       "2     124                25218.162037                  35410.519231\n",
       "3       7                 5258.428571                   5003.583333\n",
       "4      15                24441.500000                  31866.222222"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess_duration = utils.session_durations(events_df)\n",
    "\n",
    "assert sess_duration.count() == nb_users\n",
    "\n",
    "utils.get_dataframe(sess_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Daily and Monthly number of items per session\" `avg_daily_items` and`avg_monthly_items`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>avg_daily_items</th>\n",
       "      <th>avg_monthly_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100010</td>\n",
       "      <td>54.428571</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200002</td>\n",
       "      <td>82.375000</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124</td>\n",
       "      <td>196.444444</td>\n",
       "      <td>530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>28.428571</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>154.611111</td>\n",
       "      <td>367.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  avg_daily_items  avg_monthly_items\n",
       "0  100010        54.428571               85.0\n",
       "1  200002        82.375000              150.0\n",
       "2     124       196.444444              530.0\n",
       "3       7        28.428571               60.0\n",
       "4      15       154.611111              367.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_averages_df = utils.items_averages(events_df)\n",
    "assert items_averages_df.count() == nb_users\n",
    "utils.get_dataframe(items_averages_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of errors: `nb_errors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>avg(nb_errors)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  userId  avg(nb_errors)\n",
       "0    124             6.0\n",
       "1      7             1.0\n",
       "2     15             2.0\n",
       "3     54             1.0\n",
       "4    155             3.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_df = events_df.filter(events_df.page==\"Error\") \\\n",
    "            .groupBy([\"userId\"]).count() \\\n",
    "            .withColumnRenamed('count', 'nb_errors')\\\n",
    "            .groupBy([\"userId\", \"nb_errors\"]).mean().select([\"userId\", \"avg(nb_errors)\"])\n",
    "print(errors_df.count())\n",
    "utils.get_dataframe(errors_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing values with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>avg(nb_errors)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  userId  avg(nb_errors)\n",
       "0    124             6.0\n",
       "1      7             1.0\n",
       "2     15             2.0\n",
       "3     54             1.0\n",
       "4    155             3.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.window import Window as W\n",
    "errors_df = utils.impute_missing_values(spark, errors_df, 'nb_errors', events_df)\n",
    "assert errors_df.count() == nb_users\n",
    "utils.get_dataframe(errors_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender: `gender`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300023</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId gender\n",
       "0      44   None\n",
       "1      46   None\n",
       "2      41   None\n",
       "3  300023   None\n",
       "4      39   None"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_df = events_df \\\n",
    "    .select(\"userId\", \"gender\") \\\n",
    "    .dropDuplicates() \\\n",
    "    .replace(['Male', 'Female'], ['0', '1'], 'gender') \\\n",
    "    .select('userId', col('gender').cast('int'))\n",
    "assert gender_df.count() == nb_users\n",
    "utils.get_dataframe(gender_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Account level\" `last_level`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the user level can change over the time, we need to keep only the last level for the feature value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>last_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  last_level\n",
       "0  100010           0\n",
       "1  200002           1\n",
       "2     124           1\n",
       "3       7           0\n",
       "4      15           1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_df = events_df.orderBy('ts', ascending=False).groupBy('userId') \\\n",
    "                .agg(F.first('level').alias('last_level')) \\\n",
    "                .replace(['free', 'paid'], ['0', '1'], 'last_level') \\\n",
    "                .select('userId', col('last_level').cast('int'))\n",
    "\n",
    "assert level_df.count() == nb_users\n",
    "utils.get_dataframe(level_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Churn label: `churn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  churn\n",
       "0      73      1\n",
       "1  100004      1\n",
       "2      36      0\n",
       "3      94      0\n",
       "4     114      0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = events_df \\\n",
    "    .select(\"userId\", \"churn\") \\\n",
    "    .dropDuplicates() \\\n",
    "    .replace(['Churner', 'Engaged'], ['1', '0'], 'churn') \\\n",
    "    .select('userId', col('churn').cast('int'))\n",
    "\n",
    "assert label_df.count() == nb_users\n",
    "\n",
    "utils.get_dataframe(label_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avreage Number of songs per session: `avg_songs_played`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>avg_songs_played</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100010</td>\n",
       "      <td>39.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200002</td>\n",
       "      <td>64.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124</td>\n",
       "      <td>145.678571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>21.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>81.171429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  avg_songs_played\n",
       "0  100010         39.285714\n",
       "1  200002         64.500000\n",
       "2     124        145.678571\n",
       "3       7         21.428571\n",
       "4      54         81.171429"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_songs_df = events_df.where('page == \"NextSong\"') \\\n",
    "    .groupby(['userId', 'sessionId']) \\\n",
    "    .count() \\\n",
    "    .groupby(['userId']) \\\n",
    "    .avg('count') \\\n",
    "    .withColumnRenamed('avg(count)', 'avg_songs_played')\n",
    "assert avg_songs_df.count() == nb_users\n",
    "utils.get_dataframe(avg_songs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of artists each user listens to: `nb_artists`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>nb_artists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100010</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200002</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124</td>\n",
       "      <td>2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>1302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  nb_artists\n",
       "0  100010         252\n",
       "1  200002         339\n",
       "2     124        2232\n",
       "3       7         142\n",
       "4      15        1302"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_artists_df = events_df \\\n",
    "    .filter(events_df.page==\"NextSong\") \\\n",
    "    .select(\"userId\", \"artist\") \\\n",
    "    .dropDuplicates() \\\n",
    "    .groupby(\"userId\") \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed(\"count\", \"nb_artists\")\n",
    "assert nb_artists_df.count() == nb_users\n",
    "utils.get_dataframe(nb_artists_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of pages visits events `num_thumbs_down` and 'num_rolladverts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ThumbsUp 189\n",
      "ThumbsDown 179\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>did_thumbs_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  did_thumbs_up\n",
       "0  100010              0\n",
       "1  200002              0\n",
       "2     124              0\n",
       "3       7              0\n",
       "4      54              0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thumbs_up_df = events_df.select('userId','page')\\\n",
    "    .filter(events_df.page==\"Thumbs Up\") \\\n",
    "    .groupBy([\"userId\"]).count() \\\n",
    "    .withColumn(\"did_thumbs_up\", when(col(\"count\")>200, 1).otherwise(0))\\\n",
    "    .select(\"userId\", \"did_thumbs_up\")\n",
    "thumbs_down_df = events_df.filter(events_df.page==\"Thumbs Down\") \\\n",
    "    .groupBy([\"userId\"]).count() \\\n",
    "    .withColumnRenamed('count', 'num_thumbs_down')\n",
    "roll_adverts_df = events_df.filter(events_df.page==\"Roll Advert\") \\\n",
    "    .groupBy([\"userId\"]).count() \\\n",
    "    .withColumnRenamed('count', 'num_rolladverts')\n",
    "print(\"ThumbsUp\", thumbs_up_df.count())\n",
    "print(\"ThumbsDown\", thumbs_down_df.count())\n",
    "utils.get_dataframe(thumbs_up_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbs_down_df = utils.impute_missing_values(spark, thumbs_down_df, 'num_thumbs_down', events_df)\n",
    "thumbs_up_df = utils.impute_missing_values(spark, thumbs_up_df, 'num_thumbs_up', events_df)\n",
    "roll_adverts_df = utils.impute_missing_values(spark, roll_adverts_df, 'num_rolladverts', events_df)\n",
    "\n",
    "assert thumbs_up_df.count() == nb_users\n",
    "assert thumbs_down_df.count() == nb_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create features vectors by joining all extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "songs_last20days_features = sqlContext.createDataFrame(songs_last20days_features)\n",
    "sessions_last20days_features = sqlContext.createDataFrame(sessions_last20days_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>did_thumbs_up</th>\n",
       "      <th>num_thumbs_down</th>\n",
       "      <th>avg_songs_played</th>\n",
       "      <th>last_level</th>\n",
       "      <th>avg(nb_errors)</th>\n",
       "      <th>avg_daily_session_duration</th>\n",
       "      <th>avg_monthly_session_duration</th>\n",
       "      <th>avg_daily_items</th>\n",
       "      <th>avg_monthly_items</th>\n",
       "      <th>...</th>\n",
       "      <th>d_sessions_10</th>\n",
       "      <th>d_sessions_11</th>\n",
       "      <th>d_sessions_12</th>\n",
       "      <th>d_sessions_13</th>\n",
       "      <th>d_sessions_14</th>\n",
       "      <th>d_sessions_15</th>\n",
       "      <th>d_sessions_16</th>\n",
       "      <th>d_sessions_17</th>\n",
       "      <th>d_sessions_18</th>\n",
       "      <th>d_sessions_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100010</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>39.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9269.000000</td>\n",
       "      <td>9693.500000</td>\n",
       "      <td>54.428571</td>\n",
       "      <td>85.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200002</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11924.250000</td>\n",
       "      <td>21529.200000</td>\n",
       "      <td>82.375000</td>\n",
       "      <td>150.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>145.678571</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25218.162037</td>\n",
       "      <td>35410.519231</td>\n",
       "      <td>196.444444</td>\n",
       "      <td>530.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.5</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5258.428571</td>\n",
       "      <td>5003.583333</td>\n",
       "      <td>28.428571</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>136.714286</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24441.500000</td>\n",
       "      <td>31866.222222</td>\n",
       "      <td>154.611111</td>\n",
       "      <td>367.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  did_thumbs_up  num_thumbs_down  avg_songs_played  last_level  \\\n",
       "0  100010              0                5         39.285714           0   \n",
       "1  200002              0                6         64.500000           1   \n",
       "2     124              0               41        145.678571           1   \n",
       "3       7              0                1         21.428571           0   \n",
       "4      15              0               14        136.714286           1   \n",
       "\n",
       "   avg(nb_errors)  avg_daily_session_duration  avg_monthly_session_duration  \\\n",
       "0             0.0                 9269.000000                   9693.500000   \n",
       "1             0.0                11924.250000                  21529.200000   \n",
       "2             6.0                25218.162037                  35410.519231   \n",
       "3             1.0                 5258.428571                   5003.583333   \n",
       "4             2.0                24441.500000                  31866.222222   \n",
       "\n",
       "   avg_daily_items  avg_monthly_items  ...  d_sessions_10  d_sessions_11  \\\n",
       "0        54.428571               85.0  ...            0.0            0.0   \n",
       "1        82.375000              150.0  ...            0.0            0.0   \n",
       "2       196.444444              530.0  ...            0.0           56.0   \n",
       "3        28.428571               60.0  ...            0.0            0.0   \n",
       "4       154.611111              367.0  ...            0.0           85.5   \n",
       "\n",
       "   d_sessions_12  d_sessions_13  d_sessions_14  d_sessions_15  d_sessions_16  \\\n",
       "0            0.0          112.0            0.0            0.0            0.0   \n",
       "1            0.0            0.0            0.0            0.0            0.0   \n",
       "2          152.0            0.0            0.0           13.0          162.0   \n",
       "3            0.0            0.0            0.0           29.0            0.0   \n",
       "4           38.0           18.0            0.0            0.0            0.0   \n",
       "\n",
       "   d_sessions_17  d_sessions_18  d_sessions_19  \n",
       "0           72.0            0.0            0.0  \n",
       "1            0.0            0.0            0.0  \n",
       "2            0.0           58.5           89.0  \n",
       "3            0.0            0.0            0.0  \n",
       "4            0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_aggs_df = thumbs_up_df \\\n",
    "    .join(thumbs_down_df, on='userId')\\\n",
    "    .join(avg_songs_df, on='userId') \\\n",
    "    .join(level_df, on='userId') \\\n",
    "    .join(errors_df, on='userId') \\\n",
    "    .join(sess_duration, on='userId') \\\n",
    "    .join(items_averages_df, on='userId') \\\n",
    "    .join(registration_df, on='userId') \\\n",
    "    .join(nb_artists_df, on='userId') \\\n",
    "    .join(label_df, on='userId') \\\n",
    "    .join(songs_last20days_features, on='userId') \\\n",
    "    .join(roll_adverts_df, on='userId') \\\n",
    "    .join(sessions_last20days_features, on='userId')\n",
    "\n",
    "features_df = all_aggs_df.drop_duplicates()\n",
    "pd.DataFrame(features_df.take(5), columns=features_df.columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['count', 'date_index', 'last_day', 'date']\n",
    "features_df.drop(*cols);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- did_thumbs_up: long (nullable = true)\n",
      " |-- num_thumbs_down: long (nullable = true)\n",
      " |-- avg_songs_played: double (nullable = true)\n",
      " |-- last_level: integer (nullable = true)\n",
      " |-- avg(nb_errors): double (nullable = true)\n",
      " |-- avg_daily_session_duration: double (nullable = true)\n",
      " |-- avg_monthly_session_duration: double (nullable = true)\n",
      " |-- avg_daily_items: double (nullable = true)\n",
      " |-- avg_monthly_items: double (nullable = true)\n",
      " |-- registration_days: integer (nullable = true)\n",
      " |-- nb_artists: long (nullable = false)\n",
      " |-- churn: integer (nullable = true)\n",
      " |-- d_songs_0: double (nullable = true)\n",
      " |-- d_songs_1: double (nullable = true)\n",
      " |-- d_songs_2: double (nullable = true)\n",
      " |-- d_songs_3: double (nullable = true)\n",
      " |-- d_songs_4: double (nullable = true)\n",
      " |-- d_songs_5: double (nullable = true)\n",
      " |-- d_songs_6: double (nullable = true)\n",
      " |-- d_songs_7: double (nullable = true)\n",
      " |-- d_songs_8: double (nullable = true)\n",
      " |-- d_songs_9: double (nullable = true)\n",
      " |-- d_songs_10: double (nullable = true)\n",
      " |-- d_songs_11: double (nullable = true)\n",
      " |-- d_songs_12: double (nullable = true)\n",
      " |-- d_songs_13: double (nullable = true)\n",
      " |-- d_songs_14: double (nullable = true)\n",
      " |-- d_songs_15: double (nullable = true)\n",
      " |-- d_songs_16: double (nullable = true)\n",
      " |-- d_songs_17: double (nullable = true)\n",
      " |-- d_songs_18: double (nullable = true)\n",
      " |-- d_songs_19: double (nullable = true)\n",
      " |-- num_rolladverts: long (nullable = true)\n",
      " |-- d_sessions_0: double (nullable = true)\n",
      " |-- d_sessions_1: double (nullable = true)\n",
      " |-- d_sessions_2: double (nullable = true)\n",
      " |-- d_sessions_3: double (nullable = true)\n",
      " |-- d_sessions_4: double (nullable = true)\n",
      " |-- d_sessions_5: double (nullable = true)\n",
      " |-- d_sessions_6: double (nullable = true)\n",
      " |-- d_sessions_7: double (nullable = true)\n",
      " |-- d_sessions_8: double (nullable = true)\n",
      " |-- d_sessions_9: double (nullable = true)\n",
      " |-- d_sessions_10: double (nullable = true)\n",
      " |-- d_sessions_11: double (nullable = true)\n",
      " |-- d_sessions_12: double (nullable = true)\n",
      " |-- d_sessions_13: double (nullable = true)\n",
      " |-- d_sessions_14: double (nullable = true)\n",
      " |-- d_sessions_15: double (nullable = true)\n",
      " |-- d_sessions_16: double (nullable = true)\n",
      " |-- d_sessions_17: double (nullable = true)\n",
      " |-- d_sessions_18: double (nullable = true)\n",
      " |-- d_sessions_19: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "features = [col for col in features_df.columns if col not in ('userId','churn')]\n",
    "\n",
    "# Vectorizing the features\n",
    "assembler = VectorAssembler(inputCols=features, outputCol='features')\n",
    "modelvec_df = assembler.transform(features_df)\n",
    "\n",
    "modelvec_df = modelvec_df.select(col('features'), col('churn').alias('label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(modelvec_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> 4. Model training and evaluation<a id='modeling'></a></center>\n",
    "![EDA](./images/model_workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree-based algorithms are not sensitive to the scale of the features. While Logistic Regression performs poorly when features differ widely in scale. As we are going to try Random Forest and Gradient Based Trees algorithms we would not need to scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "# Scaling to mean 0 and unit std dev\n",
    "scaler = StandardScaler(inputCol='features', outputCol='scaled_features', withMean=True, withStd=True)\n",
    "model_scaler = scaler.fit(modelvec_df)\n",
    "\n",
    "modelvec_scaled = model_scaler.transform(modelvec_df)\n",
    "\n",
    "model_data = modelvec_scaled.select(col('scaled_features').alias('features'), col('label'))\n",
    "model_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size:  157\n",
      "Validation set size:  32\n"
     ]
    }
   ],
   "source": [
    "# Usually the data should be splitted in train, test and validation datasets \n",
    "#   but due to small amount of data here\n",
    "#   we will be using only train and validation data\n",
    "# 80% train and 20% validation set\n",
    "train_df, validation_df = model_data.randomSplit([0.8, 0.2], seed=42)\n",
    "print(\"Training set size: \", train_df.count())\n",
    "print(\"Validation set size: \", validation_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models training and evaluation\n",
    "We try out various models to see how they compare and perform. Then select the winning model based on the F1 score.\n",
    "\n",
    "We also perform hyperparameters tuning using `ParamGridBuilder`\n",
    "\n",
    "Given churned users are a fairly small subset, we decided to use F1 Score and accuracy metric to evalute the model performance.\n",
    "\n",
    "> `F1 score`: balances the tradeoff between precision and recall.\n",
    "\\begin{equation*}\n",
    "2 * \\frac{precision * recall}{precision + recall}\n",
    "\\end{equation*}\n",
    "    <br>\n",
    "`The area under the ROC curve (AUC)`: It assesses overall classification performance without placing more emphasis on one class over the other. So it does not reflect the minority class well. It is also scale-invariant. It measures how well predictions are ranked, rather than their absolute values.\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logisitc Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training process took 1572.9458692073822 seconds\n",
      "CPU times: user 43.9 s, sys: 22.4 s, total: 1min 6s\n",
      "Wall time: 26min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {}\n",
    "lr_model = LogisticRegression(\n",
    "    featuresCol = \"features\",\n",
    "    labelCol = \"label\")\n",
    "# Create a parameter grid for tuning the model\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "            .addGrid(lr_model.elasticNetParam, [0.1, 0.5]) \\\n",
    "            .addGrid(lr_model.maxIter, [20, 70]) \\\n",
    "            .build()\n",
    "f1_evaluator = MulticlassClassificationEvaluator(metricName=\"f1\")\n",
    "# 5-fold cross validation\n",
    "crossval_lr = CrossValidator(estimator=lr_model,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=f1_evaluator,\n",
    "                          numFolds=3)\n",
    "\n",
    "start = time()\n",
    "cv_model_lr = crossval_lr.fit(train_df)\n",
    "end = time()\n",
    "print(\"The training process took {} seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dftModel = cv_model_lr.bestModel\n",
    "# Save the best model\n",
    "cv_model_lr.bestModel.save(\"models/logistic_regression_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elasticNetParam</th>\n",
       "      <th>maxIter</th>\n",
       "      <th>AUC score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.612811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>70</td>\n",
       "      <td>0.578558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.612811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0.578558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   elasticNetParam  maxIter  AUC score\n",
       "0              0.1       20   0.612811\n",
       "1              0.1       70   0.578558\n",
       "2              0.5       20   0.612811\n",
       "3              0.5       70   0.578558"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.get_gridsearch_resuts(cv_model_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 µs, sys: 4 µs, total: 12 µs\n",
      "Wall time: 22.9 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "start = time()\n",
    "best_lr =  LogisticRegression(maxIter=20, elasticNetParam=0.1)\n",
    "end = time()\n",
    "lr_model = best_lr.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Evaluation:\n",
      "AUC: 0.6073\n",
      "F1-Score: 0.625\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "results = utils.evaluate_model(lr_model, start, end,\n",
    "                               validation_df, \"Logistic Regression\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training process took 374.3420789241791 seconds\n",
      "CPU times: user 8.88 s, sys: 4.76 s, total: 13.6 s\n",
      "Wall time: 6min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_model = RandomForestClassifier(\n",
    "        featuresCol = \"features\",\n",
    "        labelCol = \"label\",\n",
    "        maxMemoryInMB = 1000,\n",
    "        seed = 42)\n",
    "# Create a parameter grid for tuning the model\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "        .addGrid(rf_model.maxDepth, [4, 5, 7]) \\\n",
    "        .addGrid(rf_model.numTrees, [20, 50]) \\\n",
    "        .build()\n",
    "\n",
    "f1_evaluator = MulticlassClassificationEvaluator(metricName=\"f1\")\n",
    "crossval_rf = CrossValidator(estimator=rf_model,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=f1_evaluator,\n",
    "                          numFolds=3)\n",
    "\n",
    "start = time()\n",
    "cv_model_rf = crossval_rf.fit(train_df)\n",
    "end = time()\n",
    "print(\"The training process took {} seconds\".format(end - start))\n",
    "# Save the best model\n",
    "cv_model_rf.bestModel.save(\"models/random_forest_model\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Evaluation:\n",
      "AUC: 0.587\n",
      "F1-Score: 0.569\n"
     ]
    }
   ],
   "source": [
    "results = utils.evaluate_model(cv_model_rf, start, end,\n",
    "                               validation_df, \"Random Forest\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maxDepth</th>\n",
       "      <th>numTrees</th>\n",
       "      <th>AUC score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.663902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.649645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.663300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.640477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>0.659962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>0.669953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   maxDepth  numTrees  AUC score\n",
       "0         4        20   0.663902\n",
       "1         4        50   0.649645\n",
       "2         5        20   0.663300\n",
       "3         5        50   0.640477\n",
       "4         7        20   0.659962\n",
       "5         7        50   0.669953"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.get_gridsearch_resuts(cv_model_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the classifier with the best performing parameters\n",
    "best_rf =  RandomForestClassifier(maxDepth=7, numTrees=50)\n",
    "start = time()\n",
    "model_rf = best_rf.fit(train_df)\n",
    "end = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Evaluation:\n",
      "AUC: 0.6235\n",
      "F1-Score: 0.5505\n"
     ]
    }
   ],
   "source": [
    "results = utils.evaluate_model(model_rf, start, end,\n",
    "                               validation_df, \"Random Forest\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training process took 2950.441709280014 seconds\n",
      "CPU times: user 1min 6s, sys: 39.2 s, total: 1min 45s\n",
      "Wall time: 49min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gbt = GBTClassifier(seed=42,\n",
    "                    featuresCol = \"features\",\n",
    "                    labelCol = 'label')\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "        .addGrid(gbt.maxDepth, [3, 5]) \\\n",
    "        .addGrid(gbt.maxIter, [20, 70]) \\\n",
    "        .build()\n",
    "f1_evaluator = MulticlassClassificationEvaluator(metricName='f1')\n",
    "crossval_gbt = CrossValidator(estimator=gbt,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=f1_evaluator,\n",
    "                          numFolds=3)\n",
    "\n",
    "start = time()\n",
    "cv_model_gbt = crossval_gbt.fit(train_df)\n",
    "end = time()\n",
    "print('The training process took {} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maxDepth</th>\n",
       "      <th>maxIter</th>\n",
       "      <th>AUC score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.684958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>0.706143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.658231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>0.668953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   maxDepth  maxIter  AUC score\n",
       "0         3       20   0.684958\n",
       "1         3       70   0.706143\n",
       "2         5       20   0.658231\n",
       "3         5       70   0.668953"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.get_gridsearch_resuts(cv_model_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the classifier with the best performing parameters\n",
    "best_gbt =  GBTClassifier(maxIter=70, maxDepth=3)\n",
    "start = time()\n",
    "model_gbt = best_gbt.fit(train_df)\n",
    "end = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient-Boosted Trees Evaluation:\n",
      "AUC: 0.6397\n",
      "F1-Score: 0.5908\n"
     ]
    }
   ],
   "source": [
    "results = utils.evaluate_model(model_gbt, start, end,\n",
    "                               validation_df, \"Gradient-Boosted Trees\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Gradient-Boosted Trees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.550500</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.590800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.623500</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.639700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training Time</th>\n",
       "      <td>61.489262</td>\n",
       "      <td>1573.200</td>\n",
       "      <td>452.706035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Random Forest  Logistic Regression  Gradient-Boosted Trees\n",
       "F1-Score            0.550500                0.569                0.590800\n",
       "AUC                 0.623500                0.587                0.639700\n",
       "Training Time      61.489262             1573.200              452.706035"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Let’s take a step back and look at the whole journey.\n",
    "\n",
    "We wanted to predict customers churn for a hypothetical music streaming service. That using Apache Spark in all the Machine Learning workflow steps. For that we needed to have a binary classifier for the `Churner` and `Engaged` customers.\n",
    "\n",
    "For that I performed the `data cleaning` to remove log events without a user Id and checked the missing vakues in the dataset. We then did multiple `data explorations` to see how various indicators can help in distinguishing between `Churned` and `Engaged` customers. Then,I defined the customer churn indicator based on wether the user visited the any of the pages `Cancellation Confirmation` and `Downgrade Submission` or not. Next in the features engineering step I extracted categorical and numerical features. For that I used the observed indicators during the data exploration. I also explored the last 20 days of service usage to represent the behaviour of the user before the churn event based on the number of sessions and the number of songs each day.\n",
    "We split the data into training and validation data sets. And as a final step I performed model training by trying out various models varying from simple to complex ones: Logistic Regression, Random Forest and Gradient-Boosted Trees. I leveraged cross validation and grid search to fine tune the different models. Their `performance` got compared using the `AUC` metric.\n",
    "\n",
    "Gradient-Boosted Trees turned to be the winning model. We achieved about `0.64` AUC, and `0.59` F1 Score. Potentially with the whole dataset, the data exploration observation and features engineering will be more informative and stable. The model might also be enhanced.\n",
    "\n",
    "### Potential Improvements\n",
    "\n",
    "We Could try other models algorithms. But before that we would like to do more substantial data exploration and features engineering to have a more accurate model in detecting whether a user is likely to churn or not. For that we would:\n",
    "\n",
    "- Add more temporal features reflecting the service usage over the last N days.\n",
    "- Optimize the data analysis and feature engineering steps applying more Spark best practices for having efficient data exploration as well as model training and testing processes.\n",
    "- Perform data exploration on bigger batches of data subsets before using the big dataset due to the substential statistical differences with the big dataset.\n",
    "- With a higher computations power, performing a better Hyperparameter tuning for other model algorithms on Spark Cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
